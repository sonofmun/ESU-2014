{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A Short Introduction to the Pandas Package"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Pandas` is the Python Data Analysis Library from the makers of `scipy`, `numpy`, and `IPython`.  It provides the perfect data structures for textual matrices, the `Series` and the `DataFrame`.  Let's jump right in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd #the recommended import condition from pandas\n",
      "import numpy as np\n",
      "sentence = 'the dog bit the man' #our first sentence from the presentation\n",
      "token_list = sentence.split()\n",
      "type_list = list(set(token_list)) #we only want each word type listed once\n",
      "print(type_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's initialize a `Series` with these index labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser1 = pd.Series(index = type_list)\n",
      "print(ser1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to initialize it with values, we can add do this with the `data` argument or with a dictionary.  First, let's get the counts for each word in the sentence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_list = []\n",
      "count_dict = {}\n",
      "for word in type_list:\n",
      "    count_list.append(token_list.count(word))\n",
      "    count_dict[word] = token_list.count(word)\n",
      "print(count_list)\n",
      "print(type_list)\n",
      "print(count_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can create our `Series` objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ser2 = pd.Series(data = count_list, index = type_list)\n",
      "ser3 = pd.Series(count_dict)\n",
      "print(ser2)\n",
      "print(ser3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `Series` is essentially a labelled vector, here a frequency term-document vector.  In order to construct a term-document matrix, we can create another `Series` for our second sentence. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz:\n",
      "Below, write a short function that takes as its input a string of text and outputs a term-document Series."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent2 = 'the bat hit the ball'\n",
      "def td_Series(text):\n",
      "    # insert your code here to create a term-document vector for sent2\n",
      "    from collections import defaultdict\n",
      "    d = defaultdict(int)\n",
      "    for word in text.split():\n",
      "        d[word] += 1\n",
      "    s = pd.Series(d)\n",
      "    return d, s\n",
      "\n",
      "count_dict2, ser4 = td_Series(sent2)\n",
      "print(ser4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point, we have two separate Series representing two different term-document vectors.  We can bring them together to create a DataFrame, the primary object type in the Pandas package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = pd.DataFrame(data = [ser3, ser4], index = ['sent1', 'sent2'])\n",
      "print(df1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that we now have a _mxn_ term-document matrix.  We could also create the `DataFrame` by calling our `count_dict`s directly.  In this `DataFrame`, let's replace all nan values with 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = pd.DataFrame(data = [count_dict, count_dict2], index = ['sent1', 'sent2'])\n",
      "print(df2)\n",
      "df2 = df2.fillna(value = 0)\n",
      "print(df2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we can call values simply by naming the column, row name pairs.  Name the column first, then the row."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df1.ix['sent1', 'ball'])\n",
      "print(df1.ix['sent2', 'ball'])\n",
      "print(df2.ix['sent1', 'ball'])\n",
      "print(df2.ix['sent2', 'ball'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also call them by their row and column indices.  Notice that the order here is different.  First row, then column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df1.ix[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df1.ix[1,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.ix[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.ix[1,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.ix[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below are a few other things you can do with a DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.min(axis = 0)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.min(axis = 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.min(df2, axis = 1)) # numpy function works but is slightly slower"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.max(axis = 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.idxmin(axis = 1)) # index of the min"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.idxmax(axis = 1)) # index of the max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.values.max()) # max of all of the values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And simple statistics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df.describe())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.mean(axis = 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.ix[sent1].mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.std(axis = 1)) # standard deviation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, what can we do with this?  We can use, e.g., the correlation metric in Pandas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df2.irow(0).corr(df2.irow(1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, if we have the `scikit-learn` package, there is a lot more we can do.</br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Note: to install scikit-learn on Linux with Python 3.4, use the following command:</br>\n",
      "`[sudo] pip3 install git+https://github.com/scikit-learn/scikit-learn.git`.__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _tf-idf_ metric stands for 'term frequency-inverse document frequency'.  It weights the importance each word has for each document based on how often it occurs in the document and the inverse of how many documents contain it in the corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf = TfidfTransformer().fit_transform(df2)\n",
      "df_tfidf = pd.DataFrame(data = tfidf.toarray(), index = df2.index, columns = df2.columns)\n",
      "print(df_tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also measure the distance between two documents with the `pairwise_distances` function in `sklearn`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import pairwise_distances\n",
      "euclid = pairwise_distances(df2) #Euclidean distance between the two documents.\n",
      "df_euclid = pd.DataFrame(data = euclid, index = df2.index, columns = df2.index)\n",
      "print(df_euclid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz:<br>\n",
      "Now its your turn.  There are many texts in the `Data` sub-directory in this directory.  Write a function that takes as input a text file's path, reads the text from the file, splits it into its individual words, and a Series with the word types (i.e., unique words) as the index and the number of times they occur as the values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_txt(filename):\n",
      "    # write your code here\n",
      "    return s\n",
      "\n",
      "emma_Series = split_txt('./Data/austen-emma.txt')\n",
      "print(emma_Series[:20])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the first 20 members of the Series.  It looks like we have a couple of problems: capitalization and punctuation.  Edit your function below to solve these problems.<br>\n",
      "Hint: use the `punctuation` constant in the `string` library to recognize punctuation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from string import punctuation\n",
      "import re\n",
      "def split_txt(filename):\n",
      "    # write your code here\n",
      "    return s\n",
      "\n",
      "emma_Series = split_txt('./Data/austen-emma.txt')\n",
      "'''\n",
      "The following code checks whether you have successfully cleaned your corpus.\n",
      "Please do not change it.\n",
      "'''\n",
      "problems = []\n",
      "for word in emma_Series.index:\n",
      "    if re.search('[\\WA-Z]', word):\n",
      "        problems.append(word)\n",
      "print(len(problems))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the length of the `problems` list is not 0, then you are not yet finished.  Take a look at your results to check what you did wrong and edit your code to correct the problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You now have a function that can take a text, clean it, and produce a term-document array (Series).  Now, you should integrate this function into a script that will read and clean all the texts in the `./Data` folder.  You should then integrate all of the resulting Series into one large term-document matrix.  Transform this matrix into a _tf-idf_ matrix, and then run at least 5 of the metrics under `pairwise_distances` in __sklearn__.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write your code here or in a separate .py file. __Make sure I know where to find your file!__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider your results from each of these different metrics.  Is there anything that suggests which of these metrics are better for analyzing this data?\n",
      "__Write your answer in this text box, below this line.__\n",
      "Your answer:"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}