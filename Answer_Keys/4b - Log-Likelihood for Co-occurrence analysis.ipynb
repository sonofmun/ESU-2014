{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The Log-Likelihood Ratio for Statistical Evaluation of Co-occurrence Counts"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You've just heard something about the log-likelihood ratio.  Now let's code it.  Below is the equation.\n",
      "\n",
      "$log\\text{ }\\lambda = log (\\frac{L(H_1\\textrm{) # independence}}{L(H_2\\textrm{) # dependence}})$\n",
      "\n",
      "$= log\\text{ }L(c_{12}, c_1, p)\\text{ }+\\text{ }log\\text{ }L(c_2-c_{12}, N-c_1, p)$<br>\n",
      "$\\text{    }-\\text{ }log\\text{ }L(c_{12}, c_1, p_1)\\text{ }-\\text{ }log\\text{ }L(c_2-c_{12}, N-c_1, p_2)$\n",
      "\n",
      "Where $L(k,n,x) = x^k(1-x)^{n-k}$\n",
      "\n",
      "So $log\\text{ }L(c_{12}, c_1, p) = log(p^{c_{12}}(1-p)^{c_1-c_{12}})$\n",
      "\n",
      "$c_1$ = occurrences of word 1 (the target word $t$<br>\n",
      "$c_2$ = occurrences of word 2 (the co-occurrent $c$<br>\n",
      "$c_{12}$ = co-occurrences of word 1 with word 2 ($n(c,t)$)<br>\n",
      "$N$ = number of tokens in the text\n",
      "\n",
      "$p = c_2/N$<br>\n",
      "$p_1 = c_{12}/c_1$<br>\n",
      "$p_2 = (c_2-c_{12})/(N-c_1)$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Deriving the counts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We run into a problem right away, however.  The code above, which is taken directly from Manning & Sch\u00fctze, is made to work with bigrams, i.e., words that occur together.  For that purpose, we can simply use the $c_1$, $c_2$, and $N$ values from the text to calculate our answers.\n",
      "\n",
      "But we have an 8-word window instead of a 1-word window, so we need to rethink how we derive our counts.  Here, an article from <a href=''>Bullinaria and Levy</a> comes to the rescue.  We will talk about their equations to derive the counts in a second, but first we need to think about the change in thinking their method requires in us.\n",
      "\n",
      "We need to stop thinking of our text as text, because it isn't any more.  The data that we have are _derived_ from the text, but they are _not the text_.  So, if we want to do calculations on our data, we need to derive the counts from our data tables, not from our text.<br>\n",
      "And here's how:\n",
      "\n",
      "$$c_1 = f(t) = \\frac {1}{W} \\sum_c n(c,t)$$\n",
      "\n",
      "The $n(c,t)$ should look familiar to you.  $W$ is the total window size.  I.e., if you are calculating 4L-4R, $W = 8$. The equation means that the frequency of $t$ is the sum for every $c$ (co-occurrent) of the number of times that $t$ (target word) and $c$ co-occur divided by the total size of the co-occurrence window. In our `cooc_dict` in lesson 3b we calculated the number of times that every $t$ co-occurred with every $c$.  And we know the total window size.  So that means that the co-occurrence DataFrame that you derived and saved from the texts in lesson 3b has the data that we need to calculate $c_1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "Write a function below that takes as input a co-occurrence DataFrame and returns a Series with the counts of every $c_1$ based on the equation above.\n",
      "\n",
      "__Note:__ The calculation itself should take only one line of code!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def c1_counter(df):\n",
      "    # insert your code here\n",
      "    return df.sum(axis = 1)/8\n",
      "\n",
      "# Test your code below. Look at your results to make sure they make sense!\n",
      "test_df = pd.read_pickle('./Data/blake-songs.txt.cooc.pickle') # I love the way Pandas reads pickles!\n",
      "c1 = c1_counter(test_df)\n",
      "print(c1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1     1\n",
        "10    1\n",
        "12    1\n",
        "13    1\n",
        "14    1\n",
        "15    1\n",
        "17    1\n",
        "19    1\n",
        "20    1\n",
        "23    1\n",
        "25    1\n",
        "26    1\n",
        "27    1\n",
        "29    1\n",
        "3     1\n",
        "...\n",
        "\u2018sweet     1\n",
        "\u2018then      1\n",
        "\u2018they      1\n",
        "\u2018thou      1\n",
        "\u2018turn      1\n",
        "\u2018weep      3\n",
        "\u2018well      1\n",
        "\u2018what      1\n",
        "\u2018where     1\n",
        "\u2018wrath     1\n",
        "\u2019         33\n",
        "\u2019twas      1\n",
        "\u2019\u2014         1\n",
        "\u201ccome      1\n",
        "\u201d\u2019         1\n",
        "Length: 1388, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The calculation for the $c_2$ looks similar but is just slightly different.\n",
      "\n",
      "$$c_2 = f(c) = \\frac {1}{W} \\sum_t n(c,t)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "Try to interpret this equation yourself and then write a function, which will be slightly different from the `c1_counter` function, that takes as input a co-occurrence DataFrame and will calculate the counts for every $c_2$, returning a Pandas Series with these counts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def c2_counter(df):\n",
      "    # insert your code here\n",
      "    return df.sum(axis = 0)/8\n",
      "\n",
      "# Test your code below. Look at your results to make sure they make sense!\n",
      "c2 = c2_counter(test_df)\n",
      "print(c2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1     1\n",
        "10    1\n",
        "12    1\n",
        "13    1\n",
        "14    1\n",
        "15    1\n",
        "17    1\n",
        "19    1\n",
        "20    1\n",
        "23    1\n",
        "25    1\n",
        "26    1\n",
        "27    1\n",
        "29    1\n",
        "3     1\n",
        "...\n",
        "\u2018sweet     1\n",
        "\u2018then      1\n",
        "\u2018they      1\n",
        "\u2018thou      1\n",
        "\u2018turn      1\n",
        "\u2018weep      3\n",
        "\u2018well      1\n",
        "\u2018what      1\n",
        "\u2018where     1\n",
        "\u2018wrath     1\n",
        "\u2019         33\n",
        "\u2019twas      1\n",
        "\u2019\u2014         1\n",
        "\u201ccome      1\n",
        "\u201d\u2019         1\n",
        "Length: 1388, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While technically $c_1$ and $c_2$ should be computed differently because they rely on different data, for the data that we have..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(test_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "1388"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1.all() == c2.all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since our co-occurrence table is symmetrical, it doesn't matter whether we sum our data row-wise or column-wise, we get the same answer.  If the above printed `False` instead of `True`, you have done something wrong somewhere.  __Check your code!__"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since we will use the co-occurrence counts that we calculated in lesson 3b from our pickled DataFrames, the last count that we need to calculate is that for $N$.  The formula for calculating $N$ is:<br><br>\n",
      "$$N = \\frac {1}{W} \\sum_t\\sum_c n(c,t)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "Consider what this means and implement a function below that takes a co-occurrence DataFrame and returns the `float` $N$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def N_counter(df):\n",
      "    # insert your code here\n",
      "    return df.values.sum()/8\n",
      "\n",
      "# code to test your function below.  Check your results.\n",
      "N = N_counter(test_df)\n",
      "print(N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5636.5\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculate the probabilities."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "So now we have all the counts that we need, so it is time to calculate the probabilities $p$, $p_1$, and $p_2$.  Define a function below that takes as input one row of a co-occurrence DataFrame (i.e., the $c_{12}$ values for a single word type), the count Series $c_1$ and $c_2$, and the scalar $N$ and returns the Series $p$, $p_1$, and $p_2$ containing the $p$ values for the target word.\n",
      "\n",
      "__Note:__ Vectorize!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(c2.ix['the'])\n",
      "print(c2.ix['10'])\n",
      "test_df.ix['the', '10']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "357.0\n",
        "1.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "2.0"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def p_calc(c12, c1, c2, N):\n",
      "    #insert your code here\n",
      "    return c2/N, c12/c1, (c2-c12)/(N-c1)\n",
      "\n",
      "# code to test your function below. Check your results\n",
      "p, p1, p2 = p_calc(test_df.ix['the'], c1, c2, N)\n",
      "for c in test_df.index[:10]:\n",
      "    print('p for \"the\" and \"%s\" == %s' % (c, p.ix[c]))\n",
      "    print('p1 for \"the\" and \"%s\" == %s' % (c, p1.ix[c]))\n",
      "    print('p2 for \"the\" and \"%s\" == %s' % (c, p2.ix[c]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "p for \"the\" and \"1\" == 0.000177415062539\n",
        "p1 for \"the\" and \"1\" == 2.0\n",
        "p2 for \"the\" and \"1\" == -0.000177446544229\n",
        "p for \"the\" and \"10\" == 0.000177415062539\n",
        "p1 for \"the\" and \"10\" == 2.0\n",
        "p2 for \"the\" and \"10\" == -0.000177446544229\n",
        "p for \"the\" and \"12\" == 0.000177415062539\n",
        "p1 for \"the\" and \"12\" == 2.0\n",
        "p2 for \"the\" and \"12\" == -0.000177446544229\n",
        "p for \"the\" and \"13\" == 0.000177415062539\n",
        "p1 for \"the\" and \"13\" == 1.0\n",
        "p2 for \"the\" and \"13\" == 0.0\n",
        "p for \"the\" and \"14\" == 0.000177415062539\n",
        "p1 for \"the\" and \"14\" == 0.0\n",
        "p2 for \"the\" and \"14\" == 0.000177446544229\n",
        "p for \"the\" and \"15\" == 0.000177415062539\n",
        "p1 for \"the\" and \"15\" == 1.0\n",
        "p2 for \"the\" and \"15\" == 0.0\n",
        "p for \"the\" and \"17\" == 0.000177415062539\n",
        "p1 for \"the\" and \"17\" == 1.0\n",
        "p2 for \"the\" and \"17\" == 0.0\n",
        "p for \"the\" and \"19\" == 0.000177415062539\n",
        "p1 for \"the\" and \"19\" == 0.0\n",
        "p2 for \"the\" and \"19\" == 0.000177446544229\n",
        "p for \"the\" and \"20\" == 0.000177415062539\n",
        "p1 for \"the\" and \"20\" == 0.0\n",
        "p2 for \"the\" and \"20\" == 0.000177446544229\n",
        "p for \"the\" and \"23\" == 0.000177415062539\n",
        "p1 for \"the\" and \"23\" == 0.0\n",
        "p2 for \"the\" and \"23\" == 0.000177446544229\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Code the equation itself."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have all of the values that we need to actually implement the log-likelihood equation above.  But we should write one more function before we jump into solving the equation.  This function should deal with this sub-equation:\n",
      "\n",
      "$L(k,n,x) = x^k(1-x)^{n-k}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "I bet you can figure out what to do below!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def L(k,n,x):\n",
      "    #insert your code here\n",
      "    return np.power(x,k)*np.power((1-x),(n-k))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now, finally, we can code the equation itself.\n",
      "\n",
      "$= log\\text{ }L(c_{12}, c_1, p)\\text{ }+\\text{ }log\\text{ }L(c_2-c_{12}, N-c_1, p)$<br>\n",
      "$\\text{    }-\\text{ }log\\text{ }L(c_{12}, c_1, p_1)\\text{ }-\\text{ }log\\text{ }L(c_2-c_{12}, N-c_1, p_2)$\n",
      "\n",
      "Because we have broken the process down into several steps, this function should be just a short as all of the functions above.  Maybe even shorter.  The function below should return a Series with the log-likelihood values for every co-occurrent $c$ in relation to one target word $t$.\n",
      "\n",
      "__Note:__ Because we can reference global variables inside a function, we do not need to pass any arguments to our function except the target word $t$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_likelihood(t, df):\n",
      "    #insert your code here.\n",
      "    e1 = np.log(L(df.ix[t], c1, p))\n",
      "    e2 = np.log(L(c2 - test_df.ix[t], N-c1, p))\n",
      "    e3 = np.log(L(test_df.ix[t], c1, p1))\n",
      "    e4 = np.log(L(c2-test_df.ix[t], N-c1, p))\n",
      "    return e1 + e2 - e3 - e4\n",
      "\n",
      "# To test your code. Check your results.\n",
      "LL_series = log_likelihood('the')\n",
      "print(-2*LL_series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1           NaN\n",
        "10          NaN\n",
        "12          NaN\n",
        "13    17.274037\n",
        "14     0.000355\n",
        "15    17.274037\n",
        "17    17.274037\n",
        "19     0.000355\n",
        "20     0.000355\n",
        "23     0.000355\n",
        "25     0.000355\n",
        "26     0.000355\n",
        "27     0.000355\n",
        "29     0.000355\n",
        "3           NaN\n",
        "...\n",
        "\u2018sweet      0.000355\n",
        "\u2018then       0.000355\n",
        "\u2018they       0.000355\n",
        "\u2018thou       0.000355\n",
        "\u2018turn      17.274037\n",
        "\u2018weep      26.335605\n",
        "\u2018well       0.000355\n",
        "\u2018what      17.274037\n",
        "\u2018where      0.000355\n",
        "\u2018wrath     17.274037\n",
        "\u2019         139.759944\n",
        "\u2019twas       0.000355\n",
        "\u2019\u2014          0.000355\n",
        "\u201ccome      17.274037\n",
        "\u201d\u2019          0.000355\n",
        "Length: 1388, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dealing with NaN values."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You may have noticed that some of the values in our `LL_series` object are NaN values.  That means that, for whatever reason, Python was unable to compute them.  Take a look at the data you are using and the results you are getting and try to figure out why this is happening.  Take a moment to think about this problem and how you think you might be able to solve it."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Discuss, discuss, discuss, discuss."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On the basis of the discussions, edit your `log_likelihood` function below to deal with the NaN problem.\n",
      "\n",
      "__Notes:__ 64-bit float: $10^{-323}$, 128-bit float: $10^{-4950}$, `Decimal` float: $10^{-999,999,999,999,999,999}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for prob in [p, p1, p2]:\n",
      "    prob[prob >= 1] = .99\n",
      "    print(prob[prob>=1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Series([], dtype: float64)\n",
        "Series([], dtype: float64)\n",
        "Series([], dtype: float64)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_L(k,n,x):\n",
      "    #insert your code here\n",
      "    return (np.log(x)*k)+(np.log(1-x)*(n-k))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_likelihood(t, df):\n",
      "    #insert your code here.\n",
      "    c12 = df.ix[t]\n",
      "    e1 = log_L(c12, c1, p).replace([np.inf, -np.inf, np.nan], 0)\n",
      "    e2 = log_L(c2 - c12, N-c1, p).replace([np.inf, -np.inf, np.nan], 0)\n",
      "    e3 = log_L(c12, c1, p1).replace([np.inf, -np.inf, np.nan], 0)\n",
      "    e4 = log_L(c2-c12, N-c1, p2).replace([np.inf, -np.inf, np.nan], 0)\n",
      "    return -2*(e1 + e2 - e3 - e4)\n",
      "\n",
      "# To test your code. Check your results.\n",
      "LL_series = log_likelihood('the', test_df)\n",
      "print(LL_series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1     28.443999\n",
        "10    28.443999\n",
        "12    28.443999\n",
        "13    19.253759\n",
        "14     0.000355\n",
        "15    19.253759\n",
        "17    19.253759\n",
        "19     0.000355\n",
        "20     0.000355\n",
        "23     0.000355\n",
        "25     0.000355\n",
        "26     0.000355\n",
        "27     0.000355\n",
        "29     0.000355\n",
        "3     28.443999\n",
        "...\n",
        "\u2018sweet      0.000355\n",
        "\u2018then       0.000355\n",
        "\u2018they       0.000355\n",
        "\u2018thou       0.000355\n",
        "\u2018turn      19.253759\n",
        "\u2018weep      28.136961\n",
        "\u2018well       0.000355\n",
        "\u2018what      19.253759\n",
        "\u2018where      0.000355\n",
        "\u2018wrath     19.253759\n",
        "\u2019         151.952830\n",
        "\u2019twas       0.000355\n",
        "\u2019\u2014          0.000355\n",
        "\u201ccome      19.253759\n",
        "\u201d\u2019          0.000355\n",
        "Length: 1388, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Putting it all together!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "This last piece of script should be quite easy now that you have coded all of the functions above.  The last step in the process is to write a script that will go through all the target words $t$ in your corpus, calculate the log-likelihood vectors for all of them, and then put them together into a new DataFrame that has the same shape as your co-occurrence DataFrame but is, instead, filled with log-likelihood values.  I will get you started."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LL_df = pd.DataFrame(index = test_df.index, columns = test_df.columns)\n",
      "# initializing an empty DataFrame like this will reserve the necessary memory to build it\n",
      "# But you shouldn't initialize until you are ready to build it, as we are here.\n",
      "def create_LL_df(df):\n",
      "    ll_df = pd.DataFrame(index = df.index, columns = df.columns)\n",
      "    for t in df.index:\n",
      "        p, p1, p2 = p_calc(df.ix[t], c1, c2, N)\n",
      "        ll_df.ix[t] = log_likelihood(t, df)\n",
      "    return ll_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LL_df = create_LL_df(test_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(LL_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Final Activity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You have everything you need now to calculate the log-likelihood ratio for the co-occurrence DataFrames that we pickled in lesson 3b.  So write a script below that loads each of these DataFrames, runs it through the gamut of functions above, produces a full log-likelihood DataFrame, and then pickles this DataFrame as an appropriately named `.pickle` file in the directory of your choosing.\n",
      "\n",
      "__Note:__ If you have cloned the original repository on Github, don't try to `push` after having produced all of these data files.  I expect that some of them could be several hundred MB or even several GB.\n",
      "\n",
      "__Note2:__ If you are getting memory errors, just find the smallest co-occurrence DataFrame in your collection (if you are using the provided data, then probably `blake-songs` or `blake-poems`) and run the LL functions on that DF.\n",
      "\n",
      "__Note3:__ Even if you have vectorized everything perfectly, it will probably take several minutes for your code to run (maybe even much longer).  So go grab a coffee while it is running."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Insert your code here."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}