{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step we need to take in order to apply distributional semantics to our texts is to design a script that counts the number of co-occurrences for each co-occurrent $c$ within a certain range of each target word $t$.  This notebook will lead you through this process step by step.<br>\n",
      "First, we need to write a function that takes as input the complete file path of a text file, breaks our texts down into an ordered list of words, and saves it as, well, a list.  You did this is exercise 1b, so you should re-use your code as much as possible here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "from string import punctuation\n",
      "\n",
      "def txt_to_list(filename):\n",
      "    # insert your code here\n",
      "    words = []\n",
      "    [words.append(word.lower()) for word in (open(filename)).read().split()]\n",
      "    l = []\n",
      "    for word in words:\n",
      "        [l.append(w) for w in re.split('[%s]+' % punctuation, word) if w != '']\n",
      "    return l\n",
      "\n",
      "# Test your code on this short text.  Make sure to look at the results!\n",
      "tokens = txt_to_list('austen-emma-excerpt.txt')\n",
      "print(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['emma', 'by', 'jane', 'austen', '1816', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', 'sister', 's', 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, that should have been easy.  The next easy step is to write another short function that takes the list returned by the `txt_to_list` function and produces a dictionary where the keys are the individual types in the text and the values are the total counts of that type in the text.  Such a count dictionary will be necessary for our later calculations.\n",
      "\n",
      "__Hint:__ Using `Counter` here will simplify the task significantly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "def make_count_dict(l):\n",
      "    # insert your code here\n",
      "    return Counter(l)\n",
      "\n",
      "# Below tests your code.  Again, make sure to check your results.\n",
      "count_dict = make_count_dict(tokens)\n",
      "print(count_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({'of': 8, 'her': 6, 'and': 5, 'had': 5, 'the': 4, 'a': 4, 'in': 3, 'to': 3, 'mother': 2, 'with': 2, 'an': 2, 'emma': 2, 'little': 2, 'by': 2, 'i': 2, 'very': 2, 'been': 2, 'two': 1, 'jane': 1, 'volume': 1, 'his': 1, 'indistinct': 1, 'early': 1, 'remembrance': 1, 'lived': 1, 'period': 1, 'house': 1, 'supplied': 1, 'woodhouse': 1, 'daughters': 1, 'indulgent': 1, 'mistress': 1, 'marriage': 1, 'rich': 1, 'caresses': 1, 'more': 1, 'who': 1, 'world': 1, 'long': 1, 'one': 1, 'comfortable': 1, 'chapter': 1, 'fallen': 1, 'best': 1, 'consequence': 1, 'woman': 1, 'she': 1, 'or': 1, 'unite': 1, 'most': 1, 'nearly': 1, 'sister': 1, 'happy': 1, 'ago': 1, 'handsome': 1, 'disposition': 1, 'short': 1, 'austen': 1, 'blessings': 1, 'was': 1, 'governess': 1, 'affectionate': 1, 'as': 1, 'have': 1, 'died': 1, 'distress': 1, 'father': 1, '1816': 1, 'home': 1, 'youngest': 1, 's': 1, 'seemed': 1, 'some': 1, 'twenty': 1, 'from': 1, 'excellent': 1, 'clever': 1, 'affection': 1, 'place': 1, 'than': 1, 'too': 1, 'vex': 1, 'for': 1, 'years': 1, 'existence': 1})\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, the next step will be a bit more complex.  We now want to write a function that takes as input a type list and window size and returns a dictionary where the keys are the target words $t$, which are the members of your type list, and the values are _also_ dictionaries where the keys are the co-occurrents $c$, which are, again, the members of your type list, and the values for this dictionary are the number of times that $c$ co-occurs within the window around $t$.  Mathematically, it is $n(c,t)$.\n",
      "\n",
      "In the end, your dictionary should look something like this: {'the': {'the': 1000, 'aardvark': 8, 'be': 100...}}.\n",
      "\n",
      "__Hint:__ Consider using a `defaultdict` and a `Counter` for this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cooc_dict['i']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cooc_dict' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-5e5cdbf8a6b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcooc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'cooc_dict' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def make_cooc_dict(l, window_size = 4):\n",
      "    '''Takes as input a token list and a window size (default == 4).\n",
      "    The window size is the distance in words both left and right from the target word.\n",
      "    For instance, if you want 4 words left and 4 words right of your target word, window_size = 4\n",
      "    '''\n",
      "    d = defaultdict(Counter)\n",
      "    for i, word in enumerate(l):\n",
      "        w_l = []\n",
      "        [w_l.append(w) for w in l[max(i-window_size, 0):min(i+window_size+1, len(l))]]\n",
      "        w_l.remove(word)\n",
      "        d[word] += Counter(w_l)\n",
      "    # insert your code here\n",
      "    return d\n",
      "\n",
      "# Below tests your code.  Check your results.\n",
      "cooc_dict = make_cooc_dict(tokens, window_size = 4)\n",
      "#the following lines check to make sure that your cooc_dict is symmetrical\n",
      "problems = []\n",
      "[[problems.append(x,y) for x in cooc_dict[y] if cooc_dict[x][y] != cooc_dict[y][x]] for y in cooc_dict.keys()]\n",
      "problems\n",
      "#the following line checks one tough case\n",
      "cooc_dict['i'] == Counter({'chapter': 2, 'volume': 2, '1816': 2, 'woodhouse': 2, 'emma': 2, 'i': 2, \n",
      "                           'handsome': 1, 'austen': 1, 'jane': 1, 'clever': 1})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have been using dictionaries up to this point instead of Pandas Series and DataFrame objects because the former are much more memory efficient than the latter.  We should only switch over to Pandas objects when we want to start vectorizing our calculations.  This is the point at which the increased memory drain of the Pandas objects pays for itself in _speed!_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Quiz:__\n",
      "\n",
      "Now it is time to put your functions to the test with your own texts.  If you did not bring your own texts to the summer school with you, use the texts in the `Data` folder for lesson 1b.  Below, write a script that will go to the folder on your computer where your text files are, return a list of the names of all the .txt files in that folder (_Hint:_ Check out <a href='https://docs.python.org/3/library/os.html#os.listdir'>os.listdir()</a> function to help with this), and then runs each text through each of the functions you wrote above.  Finally, convert both your dictionaries ($count\\_dict$ and $cooc\\_dict$) into Pandas objects (you decide which `type` is the best for each dictionary) and save them as `.pickle` files using the `df.to_pickle()` method.\n",
      "\n",
      "As background, `pickle` serializes your Python objects, which basically means that it saves your Python objects as Python objects, e.g., it will save your dictionaries as Python dictionary objects.  This is typically both more efficient in terms of disk storage space and in processing time when saving and reloading the objects from and back into Python.\n",
      "\n",
      "__Hint:__ You might also want to check out the <a href='http://tkinter.unpythonic.net/wiki/tkFileDialog'>tkinter.filedialog</a> functions.  They open an open or save file dialog interface so that you can choose the files that you want to work with on-the-fly.  They are great tools to ease file interaction and to generalize the code you write for different purposes and different operating systems.\n",
      "\n",
      "__Hint \\#2:__ If you are running out of memory when producing your Pandas objects or pickling them, try `del` objects that you don't need any more.  For instance, once you have run the `make_count_dict` and `make_cooc_dict` functions, you don't need `types` anymore.  So type: \n",
      "\n",
      "    del types\n",
      "\n",
      "Do the same with your dictionaries once you have converted them to Pandas objects and your Pandas objects once you have pickled them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "from os.path import splitext\n",
      "import pandas as pd\n",
      "\n",
      "folder = './Data'\n",
      "texts = listdir(folder)\n",
      "for text in texts:\n",
      "    l = txt_to_list('/'.join([folder, text]))\n",
      "    cooc_dest = '/'.join([folder, ''.join([splitext(text)[0], '_cooc.pickle'])])\n",
      "    count_dest = '/'.join([folder, ''.join([splitext(text)[0], '_count.pickle'])])\n",
      "    pd.Series(make_count_dict(l)).to_pickle(count_dest)\n",
      "    pd.DataFrame(make_cooc_dict(l)).fillna(value = 0).to_pickle(cooc_dest)\n",
      "    #cooc_dicts.append(make_cooc_dict(txt_to_list('/'.join(['./Data', text]))))\n",
      "\n",
      "# insert your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}